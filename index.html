<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Jiaxuan Li's Homepage</title>

<meta name="author" content="Jiaxuan Li">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr style="padding:0px">
<td style="padding:0px">
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr style="padding:0px">
<td style="padding:2.5%;width:63%;vertical-align:middle">
<p style="text-align:center">
<name>Jiaxuan Li</name>
</p>
<p>
I am currently a final-year (2022-2025) PhD student in <a href="http://www.nlab.ci.i.u-tokyo.ac.jp/index-e.html">Nakayama Lab</a>, Department of Creative Informatics, the University of Tokyo, supervised by <a href="http://www.nlab.ci.i.u-tokyo.ac.jp/~nakayama/index_en.html">Prof. Hideki Nakayama</a>. I am supported by <a href="https://www.jsps.go.jp/j-pd/pd_saiyoichiran.html">JSPS DC2</a> Fellowship.
</p>
<p>
Before that, I received the M.Eng. degree in Electronic Engineering from Shanghai Jiao Tong University in 2022, supervised by <a href="http://www.yuyeling.com/">Prof. Yuye Ling</a>, 
and the B.Eng. degree in Communication Engineering from Shanghai University in 2019, supervised by <a href="https://www.ivp.shu.edu.cn/">Prof. Zhi Liu</a>.
</p>


<p>
My research interests include, but are not limited to: <b>Trustworthiness in Vision</b>, <b>Vision and Language</b>, and <b>Medical and Biological Vision</b>.
</p>
<p style="text-align:center">
<a href="mailto:li@nlab.ci.i.u-tokyo.ac.jp">Email</a> &nbsp/&nbsp
<a href="https://github.com/Jiaxuan-Li">GitHub</a> &nbsp/&nbsp
<a href="https://www.linkedin.com/in/jiaxuan-li-a3b35a207/">LinkedIn</a> &nbsp/&nbsp
<a href="https://www.researchgate.net/profile/Jiaxuan-Li-24">ResearchGate</a> &nbsp/&nbsp
<a href="https://scholar.google.com/citations?hl=en&user=49tpDmAAAAAJ">Scholar</a>
</p>
</td>
<td style="padding:3%;width:40%;max-width:40%">
<p></p>
<img style="width:78%;max-width:78%" alt="profile photo" src="images/ljx2024.jpg" class="hoverZoomLink"></a>
</td>
</tr>
</tbody>
</table>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
<tr>
<td style="padding:20px;width:100%;vertical-align:middle;overflow:auto">
<heading>News</heading>
<br>
<br>
<div style="height:65px;width:100%;border:0px solid #ccc;overflow:auto;">
<p>
[Oct 30, 2024] I was selected as a (<a href="https://www.daad.de/en/the-daad/postdocnet/">DAAD AInet fellow</a>) for the Postdoc-NeT-AI 11/2024 Virtual Networking Week on AI for Science at the German Academic Exchange Service (DAAD).<br>
[Jul 10, 2024] I will present an invited talk on <a href="https://jiaxuan-li.github.io/EVCap">EVCap</a> at <a href="https://miru-committee.github.io/miru2024/en/">MIRU 2024</a>, see you in Kumamoto!!<br>
[May 10, 2024] I got the <a href="https://buildyourfuture.withgoogle.com/scholarships/google-conference-scholarships">Google Travel Grants for Students in East Asia</a>.<br>
[Apr 15, 2024] I was accepted to the International Computer Vision Summer School (<a href="https://iplab.dmi.unict.it/icvss2024">ICVSS 2024</a>) held in Sicily, Italy.<br>
[Feb 27, 2024] One paper was accepted to <a href="https://cvpr.thecvf.com/Conferences/2024">CVPR 2024</a>.<br>
[Jul 14, 2023] One paper was accepted to <a href="https://iccv2023.thecvf.com">ICCV 2023</a>.<br>
[Apr 25, 2023] I was selected as a PhD research fellow (<a href="https://www.jsps.go.jp/j-pd/pd_saiyoichiran.html">DC2</a>) at the Japan Society for the Promotion of Science (JSPS).<br>
[Apr 4, 2022] I was selected as a fellow of the <a href="https://www.cis-trans.jp/spring_gx/index-e.html">SPRING GX</a> Program at the Japan Science and Technology Agency (JST).<br>
</p>
</div>
</td>
</tr>
</tbody></table>



<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr>
<td style="padding:20px;width:100%;vertical-align:middle">
<heading>Publications </heading>
</td>
</tr>
<td style="padding:20px;width:100%;vertical-align:middle">
<heading><em><font size=4">International Conferences/Journals</font></em></heading>
</td>
</tr>
</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



<tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
<td style="padding:20px;width:25%;vertical-align:middle; text-align:center;">
<img src='images/evcap.png' width="185"></div>
</td>
<td style="padding:20px;width:75%;vertical-align:middle">
<papertitle>EVCap: Retrieval-Augmented Image Captioning with External Visual-Name Memory for Open-World Comprehension</papertitle>
</a>
<br>
<strong>Jiaxuan Li</strong>*, Duc Minh Vo*,  Akihiro Sugimoto, Hideki Nakayama <br> 
<br>
<em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2024 &nbsp
<br>
<a href="https://arxiv.org/abs/2311.15879">paper</a> /
<a href="https://jiaxuan-li.github.io/EVCap">website</a> /
<a href="https://github.com/Jiaxuan-Li/EVCap">code</a>
<p></p>
</td>


<tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
<td style="padding:20px;width:25%;vertical-align:middle; text-align:center;">
<img src='images/pnd.png' width="185"></div>
</td>
<td style="padding:20px;width:75%;vertical-align:middle">
<papertitle>Partition-And-Debias: Agnostic Biases Mitigation via A Mixture of Biases-Specific Experts</papertitle>
</a>
<br>
<strong>Jiaxuan Li</strong>, Duc Minh Vo, Hideki Nakayama <br> 
<br>
<em>International Conference on Computer Vision (<b>ICCV</b>)</em>, 2023 &nbsp
<br>
<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Li_Partition-And-Debias_Agnostic_Biases_Mitigation_via_a_Mixture_of_Biases-Specific_Experts_ICCV_2023_paper.html">paper</a> /
<a href="https://github.com/Jiaxuan-Li/PnD">code</a>
<p></p>
</td>



<tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
<td style="padding:20px;width:25%;vertical-align:middle; text-align:center;">
<img src='images/mi2022r.png' width="185"></div>
</td>
<td style="padding:20px;width:75%;vertical-align:middle">
<papertitle>Multi-Scale Sparse Representation-Based Shadow Inpainting for Retinal OCT Images</papertitle>
</a>
<br>
Yaoqi Tang, Yufan Li, Hongshan Liu, <strong>Jiaxuan Li</strong>, Peiyao Jin, Yu Gan, Yuye Ling, Yikai Su <br> 
<br>
<em>SPIE Medical Imaging (<b>SPIE MI</b>)</em>, 2022 &nbsp <font color="red"><strong>(Image Processing Student Paper Award)</strong></font>
<br>
<a href="https://arxiv.org/abs/2202.11377">paper</a> / 
<a href="http://www.yuyeling.com/project/shadow-inpainting/">website</a>
<p></p>
</td>


<tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
<td style="padding:20px;width:25%;vertical-align:middle; text-align:center;">
<img src='images/boe2021r.png' width="185"></div>
</td>
<td style="padding:20px;width:75%;vertical-align:middle">
<papertitle>Multi-Scale GCN-Assisted Two-Stage Network for Joint Segmentation of Retinal Layers and Disc in Peripapillary OCT Images</papertitle>
</a>
<br>
<strong>Jiaxuan Li</strong>,
Peiyao Jin, Jianfeng Zhu, Haidong Zou, Xun Xu, Min Tang, Minwen Zhou, Yu Gan, Jiangnan He, Yuye Ling, Yikai Su <br>
<br>
<em>Biomedical Optics Express (<b>BOE</b>)</em>, 2021 &nbsp 
<br>
<a href="https://opg.optica.org/boe/fulltext.cfm?uri=boe-12-4-2204&id=449401">paper</a> /
<a href="http://www.yuyeling.com/project/mgu-net/">website</a> /
<a href="https://github.com/Jiaxuan-Li/MGU-Net">code</a>
<p></p>
</td>


<tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
<td style="padding:20px;width:25%;vertical-align:middle; text-align:center;">
<img src='images/pw2021r.png' width="182"></div>
</td>
<td style="padding:20px;width:75%;vertical-align:middle">
<papertitle>A GCN-Assisted Deep Learning Method for Peripapillary Retinal Layer Segmentation in OCT Images</papertitle>
</a>
<br>
<strong>Jiaxuan Li</strong>,
Yuye Ling, Jiangnan He, Peiyao Jin, Jianfeng Zhu, Haidong Zou, Xun Xu, Yu Gan, Yikai Su <br>
<br>
<em>SPIE Photonics West (<b>SPIE PW</b>)</em>, 2021 &nbsp 
<br>
<a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11630/1163010/A-GCN-assisted-deep-learning-method-for-peripapillary-retinal-layer/10.1117/12.2582905.short">paper</a> /
<a href="http://www.yuyeling.com/project/mgu-net/">website</a>
<p></p>
</td>



<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<td style="padding:20px;width:100%;vertical-align:middle">
<heading><em><font size=4">Domestic Conferences (non peer-reviewed)</font></em></heading>
</td>
</tr>
</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<ul>
<li>
<papertitle>Multimodal Large Language Model Meets New Knowledge: A Preliminary Study</papertitle>
</a>
<br>
Junwen Mo, <strong>Jiaxuan Li</strong>, Duc Minh Vo, Hideki Nakayama <br>
<em>The 30th Annual Meeting of the Association for Natural Language Processing (<b>NLP</b>)</em>, 2024 &nbsp  <font color="red"><strong>(Special Committee Award)</strong></font>
<br>
<br>

<li>
<papertitle>Biases Mitigation in Medical Images via Knowledge Guidance</papertitle>
</a>
<br>
<strong>Jiaxuan Li</strong>, Duc Minh Vo, Kohei Murao, Hiroyuki Abe, Tetsuo Ushiku, Shin’Ichi Satoh, Hideki Nakayama, <br>
<em>The 1st International Workshop on Embodied Semiotics (<b>EmSemi</b>)</em>, 2023 (Idea Presentation) &nbsp 
<br>
</ul>




<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr>
<td style="padding:20px;width:100%;vertical-align:middle">
<heading>Research Grants</heading>
</td></tr></table>
<ul>
<li>Japan Society for the Promotion of Science (JSPS), Grant-in-Aid for JSPS Fellows, JPY2M, Apr. 2023 - Mar. 2025</li>
<li>National Institute of Informatics (NII), NII Open Collaborative Research (Researcher), JPY1.2M, July. 2024 - Mar. 2025</li>
<li>National Institute of Informatics (NII), NII Open Collaborative Research (Researcher), JPY1M, July. 2023 - Mar. 2024</li>
<li>Japan Science and Technology Agency (JST), SPRING GX Fellowship, JPY620K, Apr. 2022 - Mar. 2023</li>
</ul>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr>
<td style="padding:20px;width:100%;vertical-align:middle">
<heading>Awards and Honors</heading>
</td></tr></table>
<ul>
<li>Special Allowance in the Final Year of JSPS Fellow, Japan Society for the Promotion of Science, 2024</li>
<li>Google Travel Grants for Students in East Asia, Google, 2024</li>
<li>Special Committee Award, the 30th Annual Meeting of the Association for Natural Language Processing, 2024</li>
<li>JSPS DC2 Research Fellowship for Young Scientists, Japan Society for the Promotion of Science, 2023</li>
<li>SPRING GX Fellowship, Japan Science and Technology Agency, 2022</li>
<li>Outstanding Graduates, Shanghai Jiao Tong University, 2022</li>
<li>COSCO Shipping Scholarship, Shanghai Jiao Tong University, 2021</li>
<li>Second Prize in “Huawei Cup” The 17th China Post-Graduate Mathematical Contest in Modeling, 2020</li>
<li>Academic Scholarship, Shanghai University, 2016</li>
</ul> 


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
<tr>
<td style="padding:20px;width:100%;vertical-align:middle">
<heading>Academic Activities</heading>
</td></tr></table>
<ul>
<li><b>Invited Talk</b> at MIRU, Kumamoto, Japan, August 2024</li>
<li><b>Poster Presentation</b> at IRCN, The University of Tokyo, Japan, July 2024</li>
<li><b>Invited Talk</b> at Knowledge and Information Research Team, AIST, Japan, July 2024</li>
<li><b>International Computer Vision Summer School</b> (ICVSS), Sicily, Italy, July 2024</li>
<li><b>Reviewer</b> at ACL ARR 2023 October, CVPR 2024, ECCV 2024</li>
</ul>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
<tr>
<td style="padding:20px;width:100%;vertical-align:middle">
<heading>Teaching Assistants</heading>
</td></tr></table>
<ul>
<li>TA in SJTU AI2614: Digital Signal and Image Processing, Spring 2021</li>
<li>TA in SJTU EE367: Fundamentals of Communication Circuits, Spring 2020</li>
<br>
<br>
</ul>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
<div id="footer">
<div id="footer-text"></div>
</div>
<p><center>
<div id="clustrmaps-widget" style="width:13%">
<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=1lhH4vIMCuw8-2SAtuOFuzYJpBPbCwg3EicoPR8PrOk"></script>
</div> 
</tbody></table>           



<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr>
<td style="padding:0px">
<br>
<p style="text-align:right;font-size:small;">
<a href="https://github.com/jonbarron/jonbarron_website">Template</a>
</p>
</td>
</tr>
</tbody></table>
</td>
</tr>
</table>
</body>

</html>
